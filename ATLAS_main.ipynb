{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHj8kA0akJQe"
      },
      "source": [
        "# **Object Detection to Detect Car, Motorbike, and Person in Traffic Lights and Real Life.** \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "## **5th Group - LM01**\n",
        "\n",
        "## **ATLAS (Automatic Traffic Light Adaptable System)**\n",
        "\n",
        "References :\n",
        "https://machinelearningknowledge.ai/yolov4-object-detection-tutorial-with-image-and-video/\n",
        "https://haiqalmuhamadalfarisi.medium.com/darknet-atau-darkflow-dua-framework-algoritma-deep-learning-yolo-you-only-look-once-3fb3552f8963\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkHsckLylhLk"
      },
      "source": [
        "### 1. Because we are going to use DarkNet Framework to implements this YOLO Algorithm, so we have to clone the GitHub Repository for the official DarkNet YOLOV4 Architecture from the famous AlexeyAB git.\n",
        "\n",
        "Why we need darknet ? As we told in our proposal, we need a framework to make our job easier to do object detection, and we decided to choose DarkNet as our framework to run YOLO Algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfxTMj_Sd7LP"
      },
      "outputs": [],
      "source": [
        "# Easily just !git clone.\n",
        "# Why we using (!) ?, because we are using GNU (one of UNIX based OS) that can easily manage file from web server\n",
        "# In this case, we access to GNU terminal using !, and git clone to clone the git repository.\n",
        " \n",
        "!git clone https://github.com/AlexeyAB/darknet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYg9aMwMmvYJ"
      },
      "source": [
        "### 2. As we know that we are going to use GPU perfomance, so don't forget to change the hardware accelerator to GPU in this google collab settings. \n",
        "\n",
        "Steps : \n",
        "Go to Edit tab, besides File tab in the top taskbar below the filename\n",
        "Click the Edit tab, and you will find \"Notebook settings\"\n",
        "Click on it, and change the hardware accelerator to GPU then save it.\n",
        "\n",
        "Why we need to use GPU ? \n",
        "Well, as we have written in the proposal that using GPU can maximize the YOLO Algorithm more efficient and faster rather than just using CPU. So, it will running even faster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEYvgK_LeCnO"
      },
      "outputs": [],
      "source": [
        "# So we have to change makefile just to make sure GPU and our OpenCV is enabled\n",
        "\n",
        "%cd darknet\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
        "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
        "!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrpDDupBqHMo"
      },
      "source": [
        "### 3. And then, we have make command to builds the DarkNet framework, which in this case convert the DarkNet code from the git into an executable file / application that ready to serve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6um5i0F9eESZ"
      },
      "outputs": [],
      "source": [
        "# Just wait because we load a lot of data to the directory. \n",
        "# The directory will be saved temporary (because we use google collab environment), and it is located on the files (config/darknet)\n",
        "\n",
        "!make"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVXg5LgPqVSr"
      },
      "source": [
        "### 4. As we related to Machine Learning and Deep Learning, it is important to import data or model weight to be trained. \n",
        "\n",
        "But in this case, YOLOV4 already provided the Model Weight that have trained before, so it will be more simple for us to detect the model.\n",
        "\n",
        "So we just using wget to get the weights, and it's the same source as we clone the git repository first. It is from AlexeyAB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozM9jw0cevqm"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF66zDFqsNaD"
      },
      "source": [
        "### 5. Import Source Video that want to be processed with YOLO Algorithm. \n",
        "\n",
        "In this case, as we want to keep it as simple as possible, we already provide 3 videos as a source video that are going to be processed.\n",
        "\n",
        "So, we import 3 videos from the drive using wget. Before that, we have to make folder / directory for the source video. \n",
        "\n",
        "The syntax that provided is referenced by Anjan Chandra Paudel on Medium.\n",
        "\n",
        "References : https://medium.com/@acpanjan/download-google-drive-files-using-wget-3c2c025a8b99"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8xz7tPpfppk"
      },
      "outputs": [],
      "source": [
        "!mkdir videoSource\n",
        "\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=12NYB9PKr85_Ean6JrHPPJn7twX9FPMHE' -O videoSource/video1.mp4\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1zxCW9o1GXEkhUV4avgsc7g4fRM3JJbav' -O videoSource/video2.mp4\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1OImvFHH2lXz5HFxHE_fLAB8gy77bkxxz' -O videoSource/video3.mp4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85TKVZqf-6fW"
      },
      "source": [
        "### 6. Run the Object Detection Algorithm to Process the Videos\n",
        "\n",
        "After we download 3 videos before, now it's time to run the object detection algorithm to detect car, motorbike, and person in the videos. \n",
        "\n",
        "Thanks to DarkNet as a framework, we don't need to write the code manually and setup the algorithm, but we can use DarkNet CLI Command for Object Detection in Videos. \n",
        "\n",
        "But before we run the command, we have to make a directory / folder to save the results of the video that have been processed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YurbikaB7Xak"
      },
      "outputs": [],
      "source": [
        "!mkdir videoResults\n",
        "\n",
        "#!./darknet detector demo <path to .data file> <path to config> <path to weights> <path to video file> -i <x> -out_filename <output file name.avi>\n",
        "\n",
        "# In this case, we only use one video to demo. Because if we use all the videos (3 videos), it will take more time and leads google collab to crash.\n",
        "# Feel free to access all of the videos on by one.\n",
        "\n",
        "!./darknet detector demo cfg/coco.data cfg/yolov4.cfg yolov4.weights -dont_show \"videoSource/video1.mp4\" -i 0 -out_filename videoResults/video1_results.mp4\n",
        "# !./darknet detector demo cfg/coco.data cfg/yolov4.cfg yolov4.weights -dont_show \"videoSource/video2.mp4\" -i 0 -out_filename videoResults/video2_results.mp4\n",
        "# !./darknet detector demo cfg/coco.data cfg/yolov4.cfg yolov4.weights -dont_show \"videoSource/video3.mp4\" -i 0 -out_filename videoResults/video3_results.mp4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpDcRiR2_-tt"
      },
      "source": [
        "### 7. See the results video by download it or move to the next step to show the video using HTML video."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "op2AHhDk_8uw"
      },
      "source": [
        "# Display the Video Results\n",
        "\n",
        "References : \n",
        "https://www.youtube.com/watch?v=C8v-XxutjW0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ex0vOhlAt3h"
      },
      "source": [
        "### 1. First, we need to install ffmpeg. It's an application that mainly focused on digital media, like music and video in many format / extension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLXlx9t8Te4X"
      },
      "outputs": [],
      "source": [
        "!pip install imageio-ffmpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SGFtz2aBhZn"
      },
      "source": [
        "### 2. Import all the important library that we need to display the video\n",
        "\n",
        "a. Imageio -> For digital media extension / library\n",
        "b. Matplotlib -> For display the pictures that contains the video\n",
        "c. Skiimage -> Transform the picture / video (resize)\n",
        "d. IPython -> Display the video as HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ry14gSazJWz4"
      },
      "outputs": [],
      "source": [
        "from skimage.transform import resize\n",
        "from IPython.display import HTML\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "\n",
        "def video_results_display(videosource):\n",
        "    # Define the figure\n",
        "    # Have 2 parameters, width and height in inches\n",
        "\n",
        "    figure = plt.figure(figsize=(11,11)); \n",
        "\n",
        "    # To store the video in the middle of the figure images / border\n",
        "    mov = [] \n",
        "\n",
        "    # We need to append the videosource into the mov one by one, using for loop\n",
        "    for i in range(len(videosource)):\n",
        "      image = plt.imshow(videosource[i], animated=True)\n",
        "      plt.axis('off'); # We need to turn this off, so there's no coordinates\n",
        "      mov.append([image])\n",
        "\n",
        "    #Create a simple animation\n",
        "    animate = animation.ArtistAnimation(figure, mov, interval = 50, repeat_delay = 1000)\n",
        "\n",
        "    plt.close()\n",
        "    return animate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bvl_JJ_DzTX"
      },
      "source": [
        "### 3. Load and append the video by convert it into HTML 5 video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9LSSMjhtFCzm"
      },
      "outputs": [],
      "source": [
        "video = imageio.mimread('videoResults/video1_results.mp4', memtest=False)  #Loading video\n",
        "#video = [resize(frame, (256, 256))[..., :3] for frame in video]    #Size adjustment (if necessary)\n",
        "HTML(video_results_display(video).to_html5_video())  #Inline video display in HTML5"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}